{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffAC9T0lrSNe",
   "metadata": {
    "id": "ffAC9T0lrSNe"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "R23VL53hopX9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R23VL53hopX9",
    "outputId": "a238fbd2-1e36-4ae5-dd58-0ca6cda3a383"
   },
   "outputs": [],
   "source": [
    "import graphs\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b55779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_hypernym\": \"\", \"_derivationally_related_form\": \"\", \"_synset_domain_topic_of\": \"\", \"_member_meronym\": \"\", \"_instance_hypernym\": \"\", \"_has_part\": \"\", \"_verb_group\": \"\", \"_also_see\": \"\", \"_member_of_domain_usage\": \"\", \"_member_of_domain_region\": \"\", \"_similar_to\": \"\"} 11\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/WN18RR/text/valid.txt', 'r') as f:\n",
    "    relations = {}\n",
    "    for line in f:\n",
    "        head, relation, tail = line.split()\n",
    "        relations[relation] = \"\"\n",
    "        \n",
    "    \n",
    "print(json.dumps(relations), len(relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a60371e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/WN18RR/text/relation_mapping.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f1/6dd_f1nj4fx0wmlm_tjfn1gr0000gn/T/ipykernel_99633/3436168128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWN18RR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/WN18RR/text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/classes/u/llm-kg-eval/graphs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, base_path, splits, verbose)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/classes/u/llm-kg-eval/graphs.py\u001b[0m in \u001b[0;36m_build_graph\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Load the mappings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mid2relation_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relation_mapping.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relation_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_json_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2relation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Initialize data structures for bookkeeping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/classes/u/llm-kg-eval/graphs.py\u001b[0m in \u001b[0;36m_load_json_mapping\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_json_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Load the map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/WN18RR/text/relation_mapping.json'"
     ]
    }
   ],
   "source": [
    "graph = graphs.WN18RR(base_path='./data/WN18RR/text', splits=['train', 'valid','test'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e05b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6e05b7e",
    "outputId": "566a25bd-868c-4da9-ec1f-faf0585033be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file train.txt\n",
      "Data loading progress: [5%]\n",
      "Data loading progress: [10%]\n",
      "Data loading progress: [15%]\n",
      "Data loading progress: [20%]\n",
      "Data loading progress: [25%]\n",
      "Data loading progress: [30%]\n",
      "Data loading progress: [35%]\n",
      "Data loading progress: [40%]\n",
      "Data loading progress: [45%]\n",
      "Data loading progress: [50%]\n",
      "Data loading progress: [55%]\n",
      "Data loading progress: [60%]\n",
      "Data loading progress: [65%]\n",
      "Data loading progress: [70%]\n",
      "Data loading progress: [75%]\n",
      "Data loading progress: [80%]\n",
      "Data loading progress: [85%]\n",
      "Loading file valid.txt\n",
      "Data loading progress: [90%]\n",
      "Loading file test.txt\n",
      "Data loading progress: [95%]\n",
      "Graph was successfully validated!\n",
      "Building the graph took 136 seconds\n"
     ]
    }
   ],
   "source": [
    "# graph = graphs.FB15k237(base_path='./data/FB15k-237', splits=['train', 'valid','test'], verbose=2)\n",
    "# https://www.cs.ubc.ca/~poole/cs532/2021/readings/Sentences2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "J2uiYjDfg-hq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2uiYjDfg-hq",
    "outputId": "d26bc660-a483-4656-82ce-669804ac4c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb31f656",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb31f656",
    "outputId": "2670f503-da91-48c6-9b49-d80fea75b4e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/30/2022 20:52:58 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "05/30/2022 20:53:04 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "05/30/2022 20:53:17 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_gpt2 = models.GPT2(model_id=\"gpt2\", device=device, verbose=1)\n",
    "model_gpt2_large = models.GPT2(model_id=\"gpt2-large\", device=device, verbose=1)\n",
    "model_bert = models.BERT(device=device, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaecb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6eaecb1",
    "outputId": "1a7d4f03-5402-43e8-86ed-24d673b36ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:03<00:34,  2.58it/s]/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:998: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 33.51096240520477\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 23.34301905632019\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.08767818562348183]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 39.035684213638305\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 26.740400397777556\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.04639912406051401]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 42.23712638616562\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 24.78905569553375\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.013292250284148195]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 36.80551244735718\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 27.326896047592165\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.03343210415009248]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:11<00:26,  2.57it/s]"
     ]
    }
   ],
   "source": [
    "p_bert = model_bert.experiment(graph, 10, 100)\n",
    "p_gpt2 = model_gpt2.experiment(graph, 10, 100)\n",
    "p_gpt2_large = model_gpt2_large.experiment(graph, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IEduVs6Krc2t",
   "metadata": {
    "id": "IEduVs6Krc2t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Proof of Concept.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs224u",
   "language": "python",
   "name": "cs224u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
