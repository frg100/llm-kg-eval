{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "875ff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5332d5",
   "metadata": {},
   "source": [
    "### KnowledgeGraph framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215811ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class KnowledgeGraph(ABC):\n",
    "    def __init__(self, name=None, verbose = 0):\n",
    "        self._name = name\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self._entities = [] # list(string)\n",
    "        self._relations = [] # list(string)\n",
    "        # np.array([(head_entity, relation, tail_entity)])\n",
    "        self._triples = np.zeros(shape=(0,3))\n",
    "        \n",
    "        self._built = False\n",
    "        \n",
    "    ####### PUBLIC #######\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def entities(self):\n",
    "        return self._entities\n",
    "    \n",
    "    @property\n",
    "    def relations(self):\n",
    "        return self._relations\n",
    "    \n",
    "    @property\n",
    "    def triples(self):\n",
    "        return self._triples\n",
    "    \n",
    "    def sample(self, k=1, negative=False):\n",
    "        if negative:\n",
    "            return self._sample_negative_loose(k)\n",
    "        else:\n",
    "            return self._sample_positive(k)\n",
    "        \n",
    "    def sample_english(self, k=1, negative=False):\n",
    "        samples = self.sample(k, negative)\n",
    "        \n",
    "        english_samples = []\n",
    "        for sample in samples:\n",
    "            head_idx, relation_idx, tail_idx = sample\n",
    "            head_id, relation_id, tail_id = self._entities[head_idx], self._relations[relation_idx], self._entities[tail_idx]\n",
    "            head, relation, tail = self._id2entity(head_id), self._id2relation(relation_id), self._id2entity(tail_id)\n",
    "            english_samples.append(relation.replace(\"{HEAD}\", head).replace(\"{TAIL}\", tail))\n",
    "            \n",
    "        return english_samples\n",
    "            \n",
    "        \n",
    "    ####### PRIVATE #######\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _id2entity(self, eid):\n",
    "        \"\"\"\n",
    "        A function that maps an entity id (eid) stored in the\n",
    "        self._entities structure to an english identifier\n",
    "        and/or description.\n",
    "        \"\"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _id2relation(self, rid):\n",
    "        \"\"\"\n",
    "        A function that maps an relation id (rid) stored in\n",
    "        the self._relations structure to an english identifier\n",
    "        and/or description.\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "        A function that builds the graph by reading in the data in\n",
    "        its current format and populating self._entities, self._relations,\n",
    "        self._triples, and at the end should set self._built to True.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def _is_built(self):\n",
    "        return self._built\n",
    "    \n",
    "    @property\n",
    "    def _num_entities(self):\n",
    "        return len(self._entities)\n",
    "    \n",
    "    @property\n",
    "    def _num_relations(self):\n",
    "        return len(self._relations)\n",
    "    \n",
    "    @property\n",
    "    def _num_triples(self):\n",
    "        return self._triples.shape[0]\n",
    "    \n",
    "    def _validate_graph(self):\n",
    "        # Make sure properties are filled out\n",
    "        assert self._built, \"The graph is not built. Please build \" \\\n",
    "        \"or check that your build_graph method sets self._build \" \\\n",
    "        \"to True after completion\"\n",
    "        \n",
    "        # Make sure shape of self._triples is [N, 3]\n",
    "        assert self._triples.shape[1] == 3, \"The _triples property\" \\\n",
    "        \"must have a shape of 3 in the second dimension. \" \\\n",
    "        \n",
    "        # Make sure all head, tail entities and relations are valid\n",
    "        head_entities = self._triples[:,0]\n",
    "        assert head_entities.max() <= len(self._entities), \"There\" \\\n",
    "        \"exists an entity in the head entities of the _triples \" \\\n",
    "        \"property that exceeds the number of available entities.\" \\\n",
    "        \n",
    "        tail_entities = self._triples[:,2]\n",
    "        assert tail_entities.max() <= len(self._entities), \"There \" \\\n",
    "        \"exists an entity in the tail entities of the _triples \" \\\n",
    "        \"property that exceeds the number of available entities.\" \\\n",
    "        \n",
    "        relations = self._triples[:,1]\n",
    "        assert relations.max() <= len(self._relations), \"There \" \\\n",
    "        \"exists an relations in the _triples \" \\\n",
    "        \"property that exceeds the number of available relations.\" \\\n",
    "        \n",
    "        for eid in self._entities:\n",
    "            assert self._id2entity(eid), f\"One of the entities ({eid}) \" \\\n",
    "            \"has no mapping.\"\n",
    "            \n",
    "        for rid in self._relations:\n",
    "            assert self._id2relation(rid), f\"One of the relations ({rid}) \" \\\n",
    "            \"has no mapping.\"\n",
    "            \n",
    "        assert self.sample(10).shape == (10, 3), \"Sampling yields the \" \\\n",
    "            \"wrong shape\"\n",
    "        \n",
    "        assert self.sample(10, negative=True).shape == (10, 3), \"Sampling \" \\\n",
    "            \"yields the wrong shape\"\n",
    "        \n",
    "        if self._verbose >= 1:\n",
    "            print(\"Graph was successfully validated!\")\n",
    "        \n",
    "    def _sample_positive(self, k):\n",
    "        triple_indices = np.random.choice(self._num_triples, k)\n",
    "        positive_samples = self._triples[triple_indices]\n",
    "        \n",
    "        return positive_samples\n",
    "    \n",
    "    def _sample_negative_loose(self, k):\n",
    "        # TODO(frg100): Make a strict version that makes sure not to\n",
    "        # add existing triples\n",
    "        head_entities = np.expand_dims(np.random.choice(self._num_entities, k), 0)\n",
    "        relations = np.expand_dims(np.random.choice(self._num_relations, k), 0)\n",
    "        tail_entities = np.expand_dims(np.random.choice(self._num_entities, k), 0)\n",
    "        \n",
    "        negative_samples = np.concatenate([head_entities, relations, tail_entities], axis=0).T\n",
    "        \n",
    "        return negative_samples\n",
    "    \n",
    "    def _load_json_mapping(self, json_path):\n",
    "        # Load the map\n",
    "        with open(json_path) as json_file:\n",
    "            return json.load(json_file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae20f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB15k237(KnowledgeGraph):\n",
    "    def __init__(self, base_path=None, splits=['train', 'test', 'valid'], verbose = 0):\n",
    "        super().__init__(name='FB15k-237', verbose = verbose)\n",
    "        \n",
    "        self._base_path = base_path\n",
    "        self._splits = splits\n",
    "        \n",
    "        self._entity_mapping = None\n",
    "        \n",
    "        start = time.time()\n",
    "        self._build_graph(verbose)\n",
    "        end = time.time()\n",
    "        if verbose >= 1:\n",
    "            print(f\"Building the graph took {round(end-start)} seconds\")    \n",
    "        \n",
    "            \n",
    "    def _id2entity(self, eid):\n",
    "        if self._entity_mapping is None:\n",
    "            assert False, \"Entity mapping must be populated\"\n",
    "            \n",
    "        if eid not in self._entity_mapping:\n",
    "            #print(f\"Entity with id ({eid}) is not mapped...\")\n",
    "            return None\n",
    "            \n",
    "        return self._entity_mapping[eid]['label']\n",
    "    \n",
    "    def _id2relation(self, rid):\n",
    "        if self._relation_mapping is None:\n",
    "            assert False, \"Relation mapping must be populated\"\n",
    "            \n",
    "        if rid not in self._relation_mapping:\n",
    "            #print(f\"Relation with id ({rid}) is not mapped...\")\n",
    "            return None\n",
    "            \n",
    "        return self._relation_mapping[rid]\n",
    "\n",
    "    def _build_graph(self, verbose):\n",
    "        # Load the mappings\n",
    "        id2entity_path = os.path.join(self._base_path, \"entity2wikidata.json\")\n",
    "        self._entity_mapping = self._load_json_mapping(id2entity_path)\n",
    "        id2relation_path = os.path.join(self._base_path, \"relation_mapping.json\")\n",
    "        self._relation_mapping = self._load_json_mapping(id2relation_path)\n",
    "        \n",
    "        # Initialize data structures for bookkeeping\n",
    "        entities = set()\n",
    "        relations = set()\n",
    "        triples = set()\n",
    "\n",
    "        num_data_points = sum(sum(1 for line in open(os.path.join(self._base_path, f\"{split}.txt\"))) for split in self._splits)\n",
    "        \n",
    "        # Load data\n",
    "        for split in self._splits:\n",
    "            path = os.path.join(self._base_path, f\"{split}.txt\")\n",
    "            if verbose >= 1:\n",
    "                print(f\"Loading file {split}.txt\")\n",
    "                \n",
    "            # Process into entities, relations, and triples\n",
    "            with open(path, 'r') as f:\n",
    "                for line in f:\n",
    "                    # Check progress\n",
    "                    last_percent_done = round((100*(self._num_triples-1))/num_data_points)\n",
    "                    percent_done = round((100*self._num_triples)/num_data_points)\n",
    "                    if verbose >= 2 and percent_done % 5 == 0 and last_percent_done % 5 != 0:\n",
    "                        print(f\"Data loading progress: [{percent_done}%]\")\n",
    "                    \n",
    "                    # Initialize data\n",
    "                    head, relation, tail = line.split()\n",
    "                    head_id, relation_id, tail_id = None, None, None\n",
    "                    \n",
    "                    # If either of the entities has no natural language translation,\n",
    "                    if not self._id2entity(head) or not self._id2entity(tail):\n",
    "                        # Don't process it\n",
    "                        continue\n",
    "                    \n",
    "                    if verbose >= 3 and percent_done % 5 == 0 and last_percent_done % 5 != 0:\n",
    "                        print(f\"{self._id2entity(head)} {relation} {self._id2entity(tail)}\")\n",
    "                    \n",
    "                    # Process head\n",
    "                    if head not in entities:\n",
    "                        entities.add(head)\n",
    "                        head_id = len(self._entities)\n",
    "                        self._entities.append(head)\n",
    "                    else:\n",
    "                        head_id = self._entities.index(head)\n",
    "                     \n",
    "                    # Process tail\n",
    "                    if tail not in entities:\n",
    "                        entities.add(tail)\n",
    "                        tail_id = len(self._entities)\n",
    "                        self._entities.append(tail)\n",
    "                    else:\n",
    "                        tail_id = self._entities.index(tail)\n",
    "                        \n",
    "                    # Process relation\n",
    "                    if relation not in relations:\n",
    "                        relations.add(relation)\n",
    "                        relation_id = len(self._relations)\n",
    "                        self._relations.append(relation)\n",
    "                    else:\n",
    "                        relation_id = self._relations.index(relation)\n",
    "\n",
    "                    # Create and add triple\n",
    "                    triple = np.array([[head_id, relation_id, tail_id]], dtype=np.int32)  \n",
    "                    if self._num_triples == 0:\n",
    "                        self._triples = triple\n",
    "                    else:\n",
    "                        self._triples = np.append(self._triples, triple, axis=0)\n",
    "                        \n",
    "        # Build and validate\n",
    "        self._built = True\n",
    "        self._validate_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219eb90e",
   "metadata": {},
   "source": [
    "### Modeling Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5534dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from happytransformer import HappyTextToText, TTSettings\n",
    "\n",
    "class LargeLanguageModel(ABC):\n",
    "    def __init__(self, name=None, verbose = 0):\n",
    "        self._name = name\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self._grammar_model = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\n",
    "        self._grammar_model_args = TTSettings(num_beams=5, min_length=1)\n",
    "        \n",
    "        self._built = False\n",
    "        \n",
    "    ####### PUBLIC #######\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    def correct_grammar(self, sentence):\n",
    "        return self._grammar_model.generate_text(f\"grammar: {sentence}\", args=self._grammar_model_args).text\n",
    "    \n",
    "    ####### PRIVATE #######\n",
    "    \n",
    "    @abstractmethod\n",
    "    def batch_perplexity(self, eid):\n",
    "        \"\"\"\n",
    "        A function that calculates a batch perplexity for a set of\n",
    "        samples.\n",
    "        \"\"\"\n",
    "        \n",
    "    @property\n",
    "    def _is_built(self):\n",
    "        return self._built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2db722b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "class GPT2(LargeLanguageModel):\n",
    "    def __init__(self, model_id=\"gpt2\", verbose = 0):\n",
    "        super().__init__(name='GPT2', verbose = verbose)\n",
    "        \n",
    "        self._model_id = model_id\n",
    "        self._model = GPT2LMHeadModel.from_pretrained(self._model_id)\n",
    "        self._tokenizer = GPT2TokenizerFast.from_pretrained(self._model_id)\n",
    "        \n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self._built = True\n",
    "        \n",
    "    def batch_perplexity(self, samples):\n",
    "        if self._verbose >= 1:\n",
    "            print(f\"[{self._model_id}] Calculating perplexity for {len(samples)} samples\")\n",
    "        perplexities = []\n",
    "        for sample in samples:\n",
    "            sample = self.correct_grammar(sample)\n",
    "            encoding = self._tokenizer(sample, return_tensors=\"pt\")\n",
    "            num_tokens = encoding.input_ids.shape[1]\n",
    "\n",
    "            nlls = []\n",
    "            for end_loc in range(1, num_tokens):\n",
    "                input_ids = encoding.input_ids[:, 0:end_loc]\n",
    "                target_ids = input_ids.clone()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self._model(input_ids, labels=target_ids)\n",
    "                    neg_log_likelihood = outputs[0] * end_loc\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            perplexity = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "            if self._verbose >= 2:\n",
    "                print(f\"[{self._model_id}] Sample <{sample}> has perplexity [{perplexity}]\")\n",
    "            perplexities.append(perplexity)\n",
    "\n",
    "        if self._verbose >= 1:\n",
    "            print(f\"[{self._model_id}] Final average perplexity: {sum(perplexities)/len(perplexities)}\")\n",
    "\n",
    "        return perplexities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6716fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "class BERT(LargeLanguageModel):\n",
    "    def __init__(self, verbose = 0):\n",
    "        super().__init__(name='BERT', verbose = verbose)\n",
    "        \n",
    "        self._name = name\n",
    "        \n",
    "        self._model_id = 'bert-base-cased'\n",
    "        self._tokenizer = BertTokenizer.from_pretrained(self._model_id)\n",
    "        self._model = BertModel.from_pretrained(self._model_id)\n",
    "        \n",
    "        self._verbose = verbose\n",
    "        \n",
    "        self._built = True\n",
    "        \n",
    "    def batch_perplexity(self, samples):\n",
    "        if self._verbose >= 1:\n",
    "            print(f\"[{self._name}] Calculating perplexity for {len(samples)} samples\")\n",
    "        perplexities = []\n",
    "        for sample in samples:\n",
    "            sample = self.correct_grammar(sample)\n",
    "            encoding = self._tokenizer(sample, return_tensors=\"pt\")\n",
    "            num_tokens = encoding.input_ids.shape[1]\n",
    "\n",
    "            nlls = []\n",
    "            for end_loc in range(1, num_tokens):\n",
    "                input_ids = encoding.input_ids[:, 0:end_loc]\n",
    "                target_ids = input_ids.clone()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self._model(input_ids, labels=target_ids)\n",
    "                    neg_log_likelihood = outputs[0] * end_loc\n",
    "\n",
    "            nlls.append(neg_log_likelihood)\n",
    "\n",
    "            perplexity = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "            if self._verbose >= 2:\n",
    "                print(f\"[{self._name}] Sample <{sample}> has perplexity [{perplexity}]\")\n",
    "            perplexities.append(perplexity)\n",
    "\n",
    "        if self._verbose >= 1:\n",
    "            print(f\"[{self._name}] Final average perplexity: {sum(perplexities)/len(perplexities)}\")\n",
    "\n",
    "        return perplexities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e5ff499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = FB15k237(base_path='./data/FB15k-237', splits=['train', 'valid','test'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57114045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/24/2022 12:55:01 - INFO - happytransformer.happy_transformer -   Using model: cpu\n",
      "05/24/2022 12:55:17 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "model_gpt2 = GPT2(model_id=\"gpt2\", verbose=2)\n",
    "model_gpt2_large = GPT2(model_id=\"gpt2-large\", verbose=2)\n",
    "#model_bert = BERT(verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e51f5592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt2] Calculating perplexity for 100 samples\n",
      "[gpt2] Sample <The GNI per capita in PPP dollars of Mauritania is measured in United States dollars.> has perplexity [104.25950622558594]\n",
      "[gpt2] Sample <The Academy Award for Best Animated Feature was given at the 85th Academy Awards.> has perplexity [16.669166564941406]\n",
      "[gpt2] Sample <The Kids Are All Right was nominated for the Golden Globe Award for Best Screenplay.> has perplexity [28.549013137817383]\n",
      "[gpt2] Sample <Rory Cochrane is Scottish American.> has perplexity [636.8055419921875]\n",
      "[gpt2] Sample <The movie The Birds was released in West Germany.> has perplexity [136.253662109375]\n",
      "[gpt2] Sample <There is a goalkeeper on the roster of the S.C. Bastia.> has perplexity [45.30856704711914]\n",
      "[gpt2] Sample <Elizabeth McGovern has been nominated for an award along with Maggie Smith.> has perplexity [58.49312210083008]\n",
      "[gpt2] Sample <The genre of the TV show \"Girls\" is black comedy.> has perplexity [47.039276123046875]\n",
      "[gpt2] Sample <The profession of Richard Matheson is actor.> has perplexity [287.5951843261719]\n",
      "[gpt2] Sample <Amy Winehouse won an award at the 54th Annual Grammy Awards.> has perplexity [29.58814239501953]\n",
      "[gpt2] Sample <Florida State University had a draft pick in the 1995 Major League Baseball draft.> has perplexity [36.226806640625]\n",
      "[gpt2] Sample <Colgate University is located in New York.> has perplexity [50.6543083190918]\n",
      "[gpt2] Sample <Denzel Washington is an actor in the TV show St. Elsewhere.> has perplexity [38.54951095581055]\n",
      "[gpt2] Sample <Bristol City F.C. currently has a forward.> has perplexity [79.90865325927734]\n",
      "[gpt2] Sample <Shatrughan Sinha was born in India.> has perplexity [84.55480194091797]\n",
      "[gpt2] Sample <The movie Skyfall was released in Norway.> has perplexity [111.98113250732422]\n",
      "[gpt2] Sample <Live and Let Die is a thriller.> has perplexity [113.2103500366211]\n",
      "[gpt2] Sample <Todd Field was born in the United States of America.> has perplexity [24.676610946655273]\n",
      "[gpt2] Sample <Diane Lane dated Timothy Hutton.> has perplexity [2090.02099609375]\n",
      "[gpt2] Sample <Edward Zwick is the director of the film \"Glory\".> has perplexity [59.60963439941406]\n",
      "[gpt2] Sample <The piano and acoustic bass guitar are often part of the same performance.> has perplexity [85.65514373779297]\n",
      "[gpt2] Sample <Doc Watson was born in the United States of America.> has perplexity [21.880233764648438]\n",
      "[gpt2] Sample <One of the featured locations in the film \"Timeline\" is Montreal.> has perplexity [52.81534957885742]\n",
      "[gpt2] Sample <Nick Jonas speaks English.> has perplexity [11440.9306640625]\n",
      "[gpt2] Sample <Clive Barker was influenced by Edgar Allan Poe.> has perplexity [113.13479614257812]\n",
      "[gpt2] Sample <Michael Bay won an award for their work, Transformers: Revenge of the Fallen.> has perplexity [38.16565704345703]\n",
      "[gpt2] Sample <The team colors of the Club Atletico San Lorenzo de Almagro is blue.> has perplexity [148.232177734375]\n",
      "[gpt2] Sample <Martin McDonagh was influenced by David Lynch.> has perplexity [104.37545013427734]\n",
      "[gpt2] Sample <The Prize is a thriller.> has perplexity [1516.399169921875]\n",
      "[gpt2] Sample <Microsoft is located in the state of Washington.> has perplexity [38.60110855102539]\n",
      "[gpt2] Sample <Unstoppable is an action film.> has perplexity [35.185184478759766]\n",
      "[gpt2] Sample <The Simon Property Group is located in the state of Indiana.> has perplexity [55.71077346801758]\n",
      "[gpt2] Sample <Sharon Stone was nominated for an award for Catwoman.> has perplexity [108.29730224609375]\n",
      "[gpt2] Sample <The movie Skyfall was released in Canada.> has perplexity [78.48910522460938]\n",
      "[gpt2] Sample <Charlotte Gibson won an award along with Victor Miller.> has perplexity [363.26116943359375]\n",
      "[gpt2] Sample <Kill Bill Volume 2 was nominated for the MTV Movie Award for Best Fight.> has perplexity [92.20887756347656]\n",
      "[gpt2] Sample <The movie Back to the Future Part II was produced by Amblin Entertainment.> has perplexity [20.56097984313965]\n",
      "[gpt2] Sample <Woody Allen was influenced by Cole Porter.> has perplexity [192.938232421875]\n",
      "[gpt2] Sample <A popular month to visit Kuala Lumpur is October.> has perplexity [214.23489379882812]\n",
      "[gpt2] Sample <The 7th United States Congress contains members that participated in the 2nd United States Congress.> has perplexity [59.99087905883789]\n",
      "[gpt2] Sample <Pat Metheny won an award at the 2001 Grammy Awards.> has perplexity [65.31172180175781]\n",
      "[gpt2] Sample <The assets of University of Hartford are measured in United States dollars.> has perplexity [85.94361877441406]\n",
      "[gpt2] Sample <Prithviraj Sukumaran is in a marriage union.> has perplexity [135.71295166015625]\n",
      "[gpt2] Sample <The University of Bristol company is located in the city of Bristol.> has perplexity [46.361289978027344]\n",
      "[gpt2] Sample <The films Deuce Bigalow: European Gigolo and Little Nicky have an award-nominated actor.> has perplexity [221.04345703125]\n",
      "[gpt2] Sample <Herbie Hancock is one of the most famous instrumentalists to play the flute.> has perplexity [33.54234313964844]\n",
      "[gpt2] Sample <The movie \"The Girl with the Dragon Tattoo\" was nominated for the Broadcast Film Critics Association Awards 2011.> has perplexity [19.302072525024414]\n",
      "[gpt2] Sample <Johann Wolfgang von Goethe was influenced by Johann Sebastian Bach.> has perplexity [20.23710060119629]\n",
      "[gpt2] Sample <Mumbai is located in India.> has perplexity [183.3075714111328]\n",
      "[gpt2] Sample <20th Century Fox distributed the film Barton Fink.> has perplexity [99.57039642333984]\n",
      "[gpt2] Sample <Laurie Metcalf has been nominated for an award along with Marcia Cross.> has perplexity [48.066410064697266]\n",
      "[gpt2] Sample <The drum and Bouzouki are often part of the same performance.> has perplexity [145.44837951660156]\n",
      "[gpt2] Sample <Steven Tyler was born in the United States of America.> has perplexity [21.891735076904297]\n",
      "[gpt2] Sample <Crossroads was nominated for the Golden Raspberry Award for Worst Original Song.> has perplexity [53.7874641418457]\n",
      "[gpt2] Sample <The profession of Eugene Levy is actor.> has perplexity [3797.0712890625]\n",
      "[gpt2] Sample <Foo Fighters has been nominated for an award along with Green Day.> has perplexity [58.79686737060547]\n",
      "[gpt2] Sample <Eddie Murphy won an award for their work, Showtime.> has perplexity [120.00521087646484]\n",
      "[gpt2] Sample <Fred Thompson lived in Alabama.> has perplexity [731.7793579101562]\n",
      "[gpt2] Sample <The profession of Tate Donovan is actor.> has perplexity [6697.14013671875]\n",
      "[gpt2] Sample <Victoria University of Wellington is located in Wellington.> has perplexity [68.90189361572266]\n",
      "[gpt2] Sample <The Soloist was executive produced by Tim Bevan.> has perplexity [165.0863494873047]\n",
      "[gpt2] Sample <Dirk Bogarde appears in the film A Bridge Too Far.> has perplexity [83.97347259521484]\n",
      "[gpt2] Sample <David Lee is an executive producer.> has perplexity [59.84901809692383]\n",
      "[gpt2] Sample <The 31st United States Congress has a member that represents the district of Maine.> has perplexity [57.133934020996094]\n",
      "[gpt2] Sample <The 1900 Summer Olympics hosted Olympic fencing.> has perplexity [619.17041015625]\n",
      "[gpt2] Sample <The specialization of an actor is a child actor.> has perplexity [206.9598388671875]\n",
      "[gpt2] Sample <Amy Winehouse is a friend of Britney Spears.> has perplexity [64.48316955566406]\n",
      "[gpt2] Sample <The profession of F. Scott Fitzgerald is writer.> has perplexity [223.5565948486328]\n",
      "[gpt2] Sample <Jeff Lynne is one of the most famous instrumentalists to play the percussion instrument.> has perplexity [49.170902252197266]\n",
      "[gpt2] Sample <The Estonian national football team currently has a defender position.> has perplexity [155.16490173339844]\n",
      "[gpt2] Sample <Leonard Dick won an award along with David Fury.> has perplexity [435.1788330078125]\n",
      "[gpt2] Sample <Peter Weir was nominated for an award for Witness.> has perplexity [173.37411499023438]\n",
      "[gpt2] Sample <The movie The Hunger Games was released in Egypt.> has perplexity [79.39572143554688]\n",
      "[gpt2] Sample <Rules of Engagement is a film produced by Scott Rudin.> has perplexity [46.628299713134766]\n",
      "[gpt2] Sample <The genre of the TV show \"Sonic X\" is drama film.> has perplexity [135.7994384765625]\n",
      "[gpt2] Sample <Megan Fox is a notable person with attention deficit hyperactivity disorder.> has perplexity [91.35211181640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt2] Sample <Patty Loveless has been nominated for an award along with Vince Gill.> has perplexity [45.83945846557617]\n",
      "[gpt2] Sample <Julia was nominated for the National Society of Film Critics Award for Best Actress.> has perplexity [23.54741668701172]\n",
      "[gpt2] Sample <Ellen Burstyn practices the religion of Catholicism.> has perplexity [308.926025390625]\n",
      "[gpt2] Sample <The profession of Wes Anderson is screenwriter.> has perplexity [1083.2369384765625]\n",
      "[gpt2] Sample <There is a significant population in Nebraska that practices United Church of Christ.> has perplexity [68.44824981689453]\n",
      "[gpt2] Sample <The fiddle and electric guitar are often part of the same performance.> has perplexity [58.51577377319336]\n",
      "[gpt2] Sample <Coming Home was released as a DVD.> has perplexity [82.7439193725586]\n",
      "[gpt2] Sample <Gustavo Cerati is in a marriage union.> has perplexity [257.96429443359375]\n",
      "[gpt2] Sample <The movie Bad Education was released in Finland.> has perplexity [376.0457763671875]\n",
      "[gpt2] Sample <Jodhaa Akbar is a drama film.> has perplexity [159.941650390625]\n",
      "[gpt2] Sample <The movie Wallace & Gromit: The Curse of the Were-Rabbit hired a visual effects supervisor.> has perplexity [33.76458740234375]\n",
      "[gpt2] Sample <The New York Yankees had a pick in the 2004 Major League Baseball draft.> has perplexity [22.442996978759766]\n",
      "[gpt2] Sample <The profession of Kathryn Joosten is an actor.> has perplexity [567.2035522460938]\n",
      "[gpt2] Sample <Howard Shore won an award at the 2005 Grammy Awards.> has perplexity [64.8160400390625]\n",
      "[gpt2] Sample <Jared Harris was born in England.> has perplexity [128.93246459960938]\n",
      "[gpt2] Sample <Rensselaer Polytechnic Institute is a school that offers the study of civil engineering.> has perplexity [13.463521957397461]\n",
      "[gpt2] Sample <Josh Holloway won an award along with Ian Somerhalder.> has perplexity [41.55632019042969]\n",
      "[gpt2] Sample <The Houston Texans are located in Houston.> has perplexity [70.08378601074219]\n",
      "[gpt2] Sample <Keanu Reeves won an award for their work, Speed.> has perplexity [128.15542602539062]\n",
      "[gpt2] Sample <Albert Jarrett was born in England.> has perplexity [193.3087921142578]\n",
      "[gpt2] Sample <The city of Princeton is located in Mercer County.> has perplexity [79.62149047851562]\n",
      "[gpt2] Sample <Claudia Cardinale is in a marriage union.> has perplexity [137.3931884765625]\n",
      "[gpt2] Sample <The format of the movie \"House of Sand and Fog\" is 35 mm film.> has perplexity [73.1729736328125]\n",
      "[gpt2] Sample <The budget of the movie The Best Years of Our Lives is in the United States dollar.> has perplexity [50.014286041259766]\n",
      "[gpt2] Final average perplexity: 382.2966003417969\n",
      "[gpt2-large] Calculating perplexity for 100 samples\n",
      "[gpt2-large] Sample <The GNI per capita in PPP dollars of Mauritania is measured in United States dollars.> has perplexity [57.99883270263672]\n",
      "[gpt2-large] Sample <The Academy Award for Best Animated Feature was given at the 85th Academy Awards.> has perplexity [11.521296501159668]\n",
      "[gpt2-large] Sample <The Kids Are All Right was nominated for the Golden Globe Award for Best Screenplay.> has perplexity [13.351083755493164]\n",
      "[gpt2-large] Sample <Rory Cochrane is Scottish American.> has perplexity [255.4786834716797]\n",
      "[gpt2-large] Sample <The movie The Birds was released in West Germany.> has perplexity [99.99967193603516]\n",
      "[gpt2-large] Sample <There is a goalkeeper on the roster of the S.C. Bastia.> has perplexity [39.261024475097656]\n",
      "[gpt2-large] Sample <Elizabeth McGovern has been nominated for an award along with Maggie Smith.> has perplexity [37.6596565246582]\n",
      "[gpt2-large] Sample <The genre of the TV show \"Girls\" is black comedy.> has perplexity [47.0806884765625]\n",
      "[gpt2-large] Sample <The profession of Richard Matheson is actor.> has perplexity [221.37730407714844]\n",
      "[gpt2-large] Sample <Amy Winehouse won an award at the 54th Annual Grammy Awards.> has perplexity [16.10378646850586]\n",
      "[gpt2-large] Sample <Florida State University had a draft pick in the 1995 Major League Baseball draft.> has perplexity [19.422988891601562]\n",
      "[gpt2-large] Sample <Colgate University is located in New York.> has perplexity [23.932723999023438]\n",
      "[gpt2-large] Sample <Denzel Washington is an actor in the TV show St. Elsewhere.> has perplexity [15.29914665222168]\n",
      "[gpt2-large] Sample <Bristol City F.C. currently has a forward.> has perplexity [31.55558204650879]\n",
      "[gpt2-large] Sample <Shatrughan Sinha was born in India.> has perplexity [13.283711433410645]\n",
      "[gpt2-large] Sample <The movie Skyfall was released in Norway.> has perplexity [154.86265563964844]\n",
      "[gpt2-large] Sample <Live and Let Die is a thriller.> has perplexity [47.14054489135742]\n",
      "[gpt2-large] Sample <Todd Field was born in the United States of America.> has perplexity [16.36202049255371]\n",
      "[gpt2-large] Sample <Diane Lane dated Timothy Hutton.> has perplexity [548.1482543945312]\n",
      "[gpt2-large] Sample <Edward Zwick is the director of the film \"Glory\".> has perplexity [31.42452621459961]\n",
      "[gpt2-large] Sample <The piano and acoustic bass guitar are often part of the same performance.> has perplexity [62.130184173583984]\n",
      "[gpt2-large] Sample <Doc Watson was born in the United States of America.> has perplexity [17.608713150024414]\n",
      "[gpt2-large] Sample <One of the featured locations in the film \"Timeline\" is Montreal.> has perplexity [38.726688385009766]\n",
      "[gpt2-large] Sample <Nick Jonas speaks English.> has perplexity [3982.595703125]\n",
      "[gpt2-large] Sample <Clive Barker was influenced by Edgar Allan Poe.> has perplexity [38.726097106933594]\n",
      "[gpt2-large] Sample <Michael Bay won an award for their work, Transformers: Revenge of the Fallen.> has perplexity [35.092491149902344]\n",
      "[gpt2-large] Sample <The team colors of the Club Atletico San Lorenzo de Almagro is blue.> has perplexity [53.28900146484375]\n",
      "[gpt2-large] Sample <Martin McDonagh was influenced by David Lynch.> has perplexity [37.306026458740234]\n",
      "[gpt2-large] Sample <The Prize is a thriller.> has perplexity [744.9943237304688]\n",
      "[gpt2-large] Sample <Microsoft is located in the state of Washington.> has perplexity [23.841215133666992]\n",
      "[gpt2-large] Sample <Unstoppable is an action film.> has perplexity [53.8210334777832]\n",
      "[gpt2-large] Sample <The Simon Property Group is located in the state of Indiana.> has perplexity [45.44552993774414]\n",
      "[gpt2-large] Sample <Sharon Stone was nominated for an award for Catwoman.> has perplexity [59.3823356628418]\n",
      "[gpt2-large] Sample <The movie Skyfall was released in Canada.> has perplexity [84.62615203857422]\n",
      "[gpt2-large] Sample <Charlotte Gibson won an award along with Victor Miller.> has perplexity [206.89234924316406]\n",
      "[gpt2-large] Sample <Kill Bill Volume 2 was nominated for the MTV Movie Award for Best Fight.> has perplexity [29.95888900756836]\n",
      "[gpt2-large] Sample <The movie Back to the Future Part II was produced by Amblin Entertainment.> has perplexity [14.193476676940918]\n",
      "[gpt2-large] Sample <Woody Allen was influenced by Cole Porter.> has perplexity [55.401329040527344]\n",
      "[gpt2-large] Sample <A popular month to visit Kuala Lumpur is October.> has perplexity [118.32229614257812]\n",
      "[gpt2-large] Sample <The 7th United States Congress contains members that participated in the 2nd United States Congress.> has perplexity [43.880615234375]\n",
      "[gpt2-large] Sample <Pat Metheny won an award at the 2001 Grammy Awards.> has perplexity [45.43520736694336]\n",
      "[gpt2-large] Sample <The assets of University of Hartford are measured in United States dollars.> has perplexity [100.05872344970703]\n",
      "[gpt2-large] Sample <Prithviraj Sukumaran is in a marriage union.> has perplexity [38.896236419677734]\n",
      "[gpt2-large] Sample <The University of Bristol company is located in the city of Bristol.> has perplexity [28.90550422668457]\n",
      "[gpt2-large] Sample <The films Deuce Bigalow: European Gigolo and Little Nicky have an award-nominated actor.> has perplexity [24.60370635986328]\n",
      "[gpt2-large] Sample <Herbie Hancock is one of the most famous instrumentalists to play the flute.> has perplexity [17.425554275512695]\n",
      "[gpt2-large] Sample <The movie \"The Girl with the Dragon Tattoo\" was nominated for the Broadcast Film Critics Association Awards 2011.> has perplexity [14.946890830993652]\n",
      "[gpt2-large] Sample <Johann Wolfgang von Goethe was influenced by Johann Sebastian Bach.> has perplexity [12.222246170043945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt2-large] Sample <Mumbai is located in India.> has perplexity [118.16363525390625]\n",
      "[gpt2-large] Sample <20th Century Fox distributed the film Barton Fink.> has perplexity [39.54825210571289]\n",
      "[gpt2-large] Sample <Laurie Metcalf has been nominated for an award along with Marcia Cross.> has perplexity [24.602293014526367]\n",
      "[gpt2-large] Sample <The drum and Bouzouki are often part of the same performance.> has perplexity [57.37322235107422]\n",
      "[gpt2-large] Sample <Steven Tyler was born in the United States of America.> has perplexity [14.699027061462402]\n",
      "[gpt2-large] Sample <Crossroads was nominated for the Golden Raspberry Award for Worst Original Song.> has perplexity [29.125059127807617]\n",
      "[gpt2-large] Sample <The profession of Eugene Levy is actor.> has perplexity [2305.234130859375]\n",
      "[gpt2-large] Sample <Foo Fighters has been nominated for an award along with Green Day.> has perplexity [39.339393615722656]\n",
      "[gpt2-large] Sample <Eddie Murphy won an award for their work, Showtime.> has perplexity [82.50799560546875]\n",
      "[gpt2-large] Sample <Fred Thompson lived in Alabama.> has perplexity [611.892333984375]\n",
      "[gpt2-large] Sample <The profession of Tate Donovan is actor.> has perplexity [2393.957275390625]\n",
      "[gpt2-large] Sample <Victoria University of Wellington is located in Wellington.> has perplexity [14.6931791305542]\n",
      "[gpt2-large] Sample <The Soloist was executive produced by Tim Bevan.> has perplexity [97.54261779785156]\n",
      "[gpt2-large] Sample <Dirk Bogarde appears in the film A Bridge Too Far.> has perplexity [46.02392578125]\n",
      "[gpt2-large] Sample <David Lee is an executive producer.> has perplexity [42.994415283203125]\n",
      "[gpt2-large] Sample <The 31st United States Congress has a member that represents the district of Maine.> has perplexity [55.65055847167969]\n",
      "[gpt2-large] Sample <The 1900 Summer Olympics hosted Olympic fencing.> has perplexity [590.4154663085938]\n",
      "[gpt2-large] Sample <The specialization of an actor is a child actor.> has perplexity [162.225341796875]\n",
      "[gpt2-large] Sample <Amy Winehouse is a friend of Britney Spears.> has perplexity [33.55132293701172]\n",
      "[gpt2-large] Sample <The profession of F. Scott Fitzgerald is writer.> has perplexity [203.49537658691406]\n",
      "[gpt2-large] Sample <Jeff Lynne is one of the most famous instrumentalists to play the percussion instrument.> has perplexity [41.09429168701172]\n",
      "[gpt2-large] Sample <The Estonian national football team currently has a defender position.> has perplexity [107.89083099365234]\n",
      "[gpt2-large] Sample <Leonard Dick won an award along with David Fury.> has perplexity [185.11245727539062]\n",
      "[gpt2-large] Sample <Peter Weir was nominated for an award for Witness.> has perplexity [132.02569580078125]\n",
      "[gpt2-large] Sample <The movie The Hunger Games was released in Egypt.> has perplexity [58.14157485961914]\n",
      "[gpt2-large] Sample <Rules of Engagement is a film produced by Scott Rudin.> has perplexity [23.483463287353516]\n",
      "[gpt2-large] Sample <The genre of the TV show \"Sonic X\" is drama film.> has perplexity [90.5226821899414]\n",
      "[gpt2-large] Sample <Megan Fox is a notable person with attention deficit hyperactivity disorder.> has perplexity [35.2667236328125]\n",
      "[gpt2-large] Sample <Patty Loveless has been nominated for an award along with Vince Gill.> has perplexity [29.980825424194336]\n",
      "[gpt2-large] Sample <Julia was nominated for the National Society of Film Critics Award for Best Actress.> has perplexity [11.0254487991333]\n",
      "[gpt2-large] Sample <Ellen Burstyn practices the religion of Catholicism.> has perplexity [138.9317626953125]\n",
      "[gpt2-large] Sample <The profession of Wes Anderson is screenwriter.> has perplexity [694.956298828125]\n",
      "[gpt2-large] Sample <There is a significant population in Nebraska that practices United Church of Christ.> has perplexity [51.449520111083984]\n",
      "[gpt2-large] Sample <The fiddle and electric guitar are often part of the same performance.> has perplexity [41.6008186340332]\n",
      "[gpt2-large] Sample <Coming Home was released as a DVD.> has perplexity [35.931358337402344]\n",
      "[gpt2-large] Sample <Gustavo Cerati is in a marriage union.> has perplexity [135.9561004638672]\n",
      "[gpt2-large] Sample <The movie Bad Education was released in Finland.> has perplexity [246.8888702392578]\n",
      "[gpt2-large] Sample <Jodhaa Akbar is a drama film.> has perplexity [68.04881286621094]\n",
      "[gpt2-large] Sample <The movie Wallace & Gromit: The Curse of the Were-Rabbit hired a visual effects supervisor.> has perplexity [9.275410652160645]\n",
      "[gpt2-large] Sample <The New York Yankees had a pick in the 2004 Major League Baseball draft.> has perplexity [13.078193664550781]\n",
      "[gpt2-large] Sample <The profession of Kathryn Joosten is an actor.> has perplexity [224.20620727539062]\n",
      "[gpt2-large] Sample <Howard Shore won an award at the 2005 Grammy Awards.> has perplexity [59.85615158081055]\n",
      "[gpt2-large] Sample <Jared Harris was born in England.> has perplexity [109.2480697631836]\n",
      "[gpt2-large] Sample <Rensselaer Polytechnic Institute is a school that offers the study of civil engineering.> has perplexity [10.953485488891602]\n",
      "[gpt2-large] Sample <Josh Holloway won an award along with Ian Somerhalder.> has perplexity [43.47272872924805]\n",
      "[gpt2-large] Sample <The Houston Texans are located in Houston.> has perplexity [44.10163497924805]\n",
      "[gpt2-large] Sample <Keanu Reeves won an award for their work, Speed.> has perplexity [72.7658462524414]\n",
      "[gpt2-large] Sample <Albert Jarrett was born in England.> has perplexity [130.44921875]\n",
      "[gpt2-large] Sample <The city of Princeton is located in Mercer County.> has perplexity [38.817962646484375]\n",
      "[gpt2-large] Sample <Claudia Cardinale is in a marriage union.> has perplexity [64.58512115478516]\n",
      "[gpt2-large] Sample <The format of the movie \"House of Sand and Fog\" is 35 mm film.> has perplexity [30.843814849853516]\n",
      "[gpt2-large] Sample <The budget of the movie The Best Years of Our Lives is in the United States dollar.> has perplexity [36.0294189453125]\n",
      "[gpt2-large] Final average perplexity: 177.09014892578125\n"
     ]
    }
   ],
   "source": [
    "samples = graph.sample_english(100)\n",
    "gpt2_pos_perplexity = model_gpt2.batch_perplexity(samples)\n",
    "gpt2_large_pos_perplexity = model_gpt2_large.batch_perplexity(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gpt2] Calculating perplexity for 100 samples\n",
      "[gpt2] Sample <Saskatoon was a peer of Gods and Monsters.> has perplexity [514.7250366210938]\n",
      "[gpt2] Sample <One of the sports at the Nelson Riddle was Portland State University.> has perplexity [187.6018829345703]\n",
      "[gpt2] Sample <The release region of the film \"Minnesota Golden Gophers men's basketball\" is Patricia Arquette.> has perplexity [101.3570556640625]\n",
      "[gpt2] Sample <Home Alone is a Manmohan Krishna.> has perplexity [997.503173828125]\n",
      "[gpt2] Sample <Ecuador impersonated Marie Antoinette.> has perplexity [334.19293212890625]\n",
      "[gpt2] Sample <The administrative parent of A.C. ChievoVerona is lounge music.> has perplexity [661.1280517578125]\n",
      "[gpt2] Sample <Michael Redgrave wrote the music for the movie \"abdominal pain\".> has perplexity [124.79692840576172]\n"
     ]
    }
   ],
   "source": [
    "negative_samples = graph.sample_english(100, negative=True)\n",
    "gpt2_neg_perplexity = model_gpt2.batch_perplexity(negative_samples)\n",
    "gpt2_large_neg_perplexity = model_gpt2_large.batch_perplexity(negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_models(samples, model_a, perplexities_a, model_b, perplexities_b):\n",
    "    f, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.set(yscale=\"log\")\n",
    "\n",
    "    model_one_ppx = np.array([ppx.item() for ppx in perplexities_a])\n",
    "    model_two_ppx = np.array([ppx.item() for ppx in perplexities_b])\n",
    "\n",
    "    sort_order = np.argsort(model_one_ppx).astype(int)\n",
    "\n",
    "    sns.lineplot(x=samples, y=model_one_ppx[sort_order], label=model_a)\n",
    "    sns.lineplot(x=samples, y=model_two_ppx[sort_order], label=model_b)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.title(\"Comparing perplexity on sample sentences between two models\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "compare_models(samples, 'GPT2', gpt2_pos_perplexity, \"GPT2-Large\", gpt2_large_pos_perplexity)\n",
    "compare_models(negative_samples, 'GPT2', gpt2_neg_perplexity, \"GPT2-Large\", gpt2_large_neg_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2626df",
   "metadata": {},
   "source": [
    "### Random Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(weights_name)\n",
    "bert_model = BertModel.from_pretrained(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.batch_encode_plus(\n",
    "    graph.sample_english(10),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d81cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_perplexity(samples, verbose=0):\n",
    "    print(f\"Calculating perplexity for {len(samples)} samples\")\n",
    "    perplexities = []\n",
    "    for sample in samples:\n",
    "        encoding = tokenizer(sample, return_tensors=\"pt\")\n",
    "        num_tokens = encoding.input_ids.shape[1]\n",
    "\n",
    "        nlls = []\n",
    "        for end_loc in range(1, num_tokens):\n",
    "            input_ids = encoding.input_ids[:, 0:end_loc]\n",
    "            target_ids = input_ids.clone()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, labels=target_ids)\n",
    "                neg_log_likelihood = outputs[0] * end_loc\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        perplexity = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "        if verbose >= 2:\n",
    "            print(f\"Sample <{sample}> has perplexity [{perplexity}]\")\n",
    "        perplexities.append(perplexity)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print(f\"Final average perplexity: {sum(perplexities)/len(perplexities)}\")\n",
    "        \n",
    "    return perplexities\n",
    "\n",
    "batch_perplexity(graph.sample_english(10, negative=False), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "encodings = tokenizer(\"\\n\\n\".join(graph.sample_english(10)), return_tensors=\"pt\")\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_length = model.config.n_positions\n",
    "stride = 1\n",
    "\n",
    "nlls = []\n",
    "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
    "    begin_loc = max(i + stride - max_length, 0)\n",
    "    end_loc = min(i + stride, encodings.input_ids.size(1))\n",
    "    trg_len = end_loc - i  # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(begin_loc, end_loc)\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "        neg_log_likelihood = outputs[0] * trg_len\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "ppl = torch.exp(torch.stack(nlls).sum() / end_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d221a",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = FB15k237(base_path='./data/FB15k-237', splits=['train', 'valid','test'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.sample_english(10, negative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1701e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff743083",
   "metadata": {},
   "source": [
    "### Random Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path='./data/FB15k-237'\n",
    "\n",
    "# mapping = {}\n",
    "\n",
    "# # Load file if it exists\n",
    "# json_path = os.path.join(base_path, \"relation_mapping.json\")\n",
    "\n",
    "# if os.path.exists(json_path):\n",
    "#     json_file_read = open(json_path, 'r')\n",
    "#     mapping = json.load(json_file_read)\n",
    "#     json_file_read.close()\n",
    "\n",
    "\n",
    "# # for rel in graph.relations:\n",
    "# #     if rel not in mapping:\n",
    "# #         relations_done = len(mapping.keys())\n",
    "# #         relations_total = len(graph.relations)\n",
    "# #         relations_left = relations_total - relations_done\n",
    "# #         print(f\"[{round(100*(relations_done/relations_total), 2)}%] done describing relations ({relations_left} left)\")\n",
    "        \n",
    "# #         instance_idx = np.where(graph.triples[:, 1] == graph.relations.index(rel))[0][0]\n",
    "# #         head, relation, tail = graph.triples[instance_idx]\n",
    "# #         head, tail = graph._mid2entity(graph.entities[head]), graph._mid2entity(graph.entities[tail])\n",
    "        \n",
    "# #         format_string = input(f\"{head} {rel} {tail}: \")\n",
    "# #         mapping[rel] = format_string\n",
    "# #         json_file_write = open(json_path, 'w')\n",
    "# #         json.dump(mapping, json_file_write)\n",
    "# #         json_file_write.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset using the functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def see_relation_examples(relation, k = 1):\n",
    "#     instance_indices = np.where(graph.triples[:, 1] == graph.relations.index(rel))[0][:k]\n",
    "#     samples = graph.triples[instance_indices]\n",
    "#     for sample in samples:\n",
    "#         h, r, t = sample\n",
    "#         print(graph._id2entity(graph.entities[h]), graph.relations[r], graph._id2entity(graph.entities[t]))\n",
    "    \n",
    "# see_relation_examples('/award/award_winner/awards_won./award/award_honor/award_winner', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph.relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224u",
   "language": "python",
   "name": "cs224u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
