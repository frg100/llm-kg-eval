{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffAC9T0lrSNe",
   "metadata": {
    "id": "ffAC9T0lrSNe"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "R23VL53hopX9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R23VL53hopX9",
    "outputId": "a238fbd2-1e36-4ae5-dd58-0ca6cda3a383"
   },
   "outputs": [],
   "source": [
    "import graphs\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043cb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('./data/WN18RR/text/valid.txt', 'r') as f:\n",
    "#     relations = {}\n",
    "#     for line in f:\n",
    "#         head, relation, tail = line.split()\n",
    "#         relations[relation] = \"\"\n",
    "        \n",
    "    \n",
    "# print(json.dumps(relations), len(relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "535303cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file train.txt\n",
      "Data loading progress: [5%]\n",
      "Data loading progress: [10%]\n",
      "Data loading progress: [15%]\n",
      "Data loading progress: [20%]\n",
      "Data loading progress: [25%]\n",
      "Data loading progress: [30%]\n",
      "Data loading progress: [35%]\n",
      "Data loading progress: [40%]\n",
      "Data loading progress: [45%]\n",
      "Data loading progress: [50%]\n",
      "Data loading progress: [55%]\n",
      "Data loading progress: [60%]\n",
      "Data loading progress: [65%]\n",
      "Data loading progress: [70%]\n",
      "Data loading progress: [75%]\n",
      "Data loading progress: [80%]\n",
      "Data loading progress: [85%]\n",
      "Data loading progress: [90%]\n",
      "Loading file valid.txt\n",
      "Data loading progress: [95%]\n",
      "Loading file test.txt\n",
      "Data loading progress: [100%]\n",
      "Graph was successfully validated!\n",
      "Building the graph took 22 seconds\n"
     ]
    }
   ],
   "source": [
    "graph = graphs.WN18RR(base_path='./data/WN18RR/text', splits=['train', 'valid','test'], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f62bf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insufficiency is in or took place in chrysosplenium',\n",
       " 'masher is in or took place in color tube',\n",
       " 'The word fumariaceae is similar to march',\n",
       " 'The word pilot is a kind of adams',\n",
       " 'The word vaccination is part of ready',\n",
       " 'recapture is a similar kind of action to verdict',\n",
       " 'The word apposition is similar to ground squirrel',\n",
       " 'The word san juan mountains is related to junior',\n",
       " 'The word haggle is a kind of ball field',\n",
       " 'The word farce is a part of pencil cedar']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.sample_english(10, negative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e05b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6e05b7e",
    "outputId": "566a25bd-868c-4da9-ec1f-faf0585033be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file train.txt\n",
      "Data loading progress: [5%]\n",
      "Data loading progress: [10%]\n",
      "Data loading progress: [15%]\n",
      "Data loading progress: [20%]\n",
      "Data loading progress: [25%]\n",
      "Data loading progress: [30%]\n",
      "Data loading progress: [35%]\n",
      "Data loading progress: [40%]\n",
      "Data loading progress: [45%]\n",
      "Data loading progress: [50%]\n",
      "Data loading progress: [55%]\n",
      "Data loading progress: [60%]\n",
      "Data loading progress: [65%]\n",
      "Data loading progress: [70%]\n",
      "Data loading progress: [75%]\n",
      "Data loading progress: [80%]\n",
      "Data loading progress: [85%]\n",
      "Loading file valid.txt\n",
      "Data loading progress: [90%]\n",
      "Loading file test.txt\n",
      "Data loading progress: [95%]\n",
      "Graph was successfully validated!\n",
      "Building the graph took 136 seconds\n"
     ]
    }
   ],
   "source": [
    "# graph = graphs.FB15k237(base_path='./data/FB15k-237', splits=['train', 'valid','test'], verbose=2)\n",
    "# https://www.cs.ubc.ca/~poole/cs532/2021/readings/Sentences2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "J2uiYjDfg-hq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2uiYjDfg-hq",
    "outputId": "d26bc660-a483-4656-82ce-669804ac4c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb31f656",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb31f656",
    "outputId": "2670f503-da91-48c6-9b49-d80fea75b4e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/30/2022 20:52:58 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "05/30/2022 20:53:04 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "05/30/2022 20:53:17 - INFO - happytransformer.happy_transformer -   Using model: cuda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_gpt2 = models.GPT2(model_id=\"gpt2\", device=device, verbose=1)\n",
    "model_gpt2_large = models.GPT2(model_id=\"gpt2-large\", device=device, verbose=1)\n",
    "model_bert = models.BERT(device=device, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaecb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6eaecb1",
    "outputId": "1a7d4f03-5402-43e8-86ed-24d673b36ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:03<00:34,  2.58it/s]/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:998: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 33.51096240520477\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 23.34301905632019\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.08767818562348183]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 39.035684213638305\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 26.740400397777556\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.04639912406051401]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 42.23712638616562\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 24.78905569553375\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.013292250284148195]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 36.80551244735718\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:36<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT] Final average perplexity: 27.326896047592165\n",
      "The power of BERT on FB15k-237 (100 samples) is: [0.03343210415009248]\n",
      "[BERT] Calculating perplexity for 100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:11<00:26,  2.57it/s]"
     ]
    }
   ],
   "source": [
    "p_bert = model_bert.experiment(graph, 10, 100)\n",
    "p_gpt2 = model_gpt2.experiment(graph, 10, 100)\n",
    "p_gpt2_large = model_gpt2_large.experiment(graph, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IEduVs6Krc2t",
   "metadata": {
    "id": "IEduVs6Krc2t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Proof of Concept.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs224u",
   "language": "python",
   "name": "cs224u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
